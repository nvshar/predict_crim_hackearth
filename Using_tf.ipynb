{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('criminal_train.csv')\n",
    "#df.head()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.drop(['Criminal','PERID'],axis=1))\n",
    "scaled_features = scaler.transform(df.drop(['Criminal','PERID'],axis=1))\n",
    "X_train = pd.DataFrame(scaled_features,columns=df.columns[1:-1])\n",
    "y_train=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train= np_utils.to_categorical(y_train,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45718, 70)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(\"float\",shape=[None,70])\n",
    "y=tf.placeholder(\"float\",shape=[None,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "epochs=50\n",
    "batch_size=50\n",
    "n_samples=45718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=70\n",
    "n_lay1=32\n",
    "n_lay2=32\n",
    "n_lay3=16\n",
    "n_lay4=8\n",
    "n_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x,weight,bias):\n",
    "    \n",
    "    layer1=tf.add(tf.matmul(x,weight['l1']),bias['l1'])\n",
    "    layer1=tf.nn.relu(layer1)\n",
    "    layer2=tf.add(tf.matmul(layer1,weight['l2']),bias['l2'])\n",
    "    layer2=tf.nn.relu(layer2)\n",
    "    layer3=tf.add(tf.matmul(layer2,weight['l3']),bias['l3'])\n",
    "    layer3=tf.nn.relu(layer3)\n",
    "    layer4=tf.add(tf.matmul(layer3,weight['l4']),bias['l4'])\n",
    "    layer4=tf.nn.relu(layer4)\n",
    "    out_layer=tf.matmul(layer4,weight['out'])+bias['out']\n",
    "    \n",
    "    return out_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight={\n",
    "    'l1':tf.Variable(tf.random_normal([n_input,n_lay1])),\n",
    "    'l2':tf.Variable(tf.random_normal([n_lay1,n_lay2])),\n",
    "    'l3':tf.Variable(tf.random_normal([n_lay2,n_lay3])),\n",
    "    'l4':tf.Variable(tf.random_normal([n_lay3,n_lay4])),\n",
    "    'out':tf.Variable(tf.random_normal([n_lay4,n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias={\n",
    "    'l1':tf.Variable(tf.random_normal([n_lay1])),\n",
    "    'l2':tf.Variable(tf.random_normal([n_lay2])),\n",
    "    'l3':tf.Variable(tf.random_normal([n_lay3])),\n",
    "    'l4':tf.Variable(tf.random_normal([n_lay4])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost=13.2310\n",
      "Epoch: 2 cost=0.5245\n",
      "Epoch: 3 cost=0.2746\n",
      "Epoch: 4 cost=0.2564\n",
      "Epoch: 5 cost=0.2484\n",
      "Epoch: 6 cost=0.2455\n",
      "Epoch: 7 cost=0.2445\n",
      "Epoch: 8 cost=0.2440\n",
      "Epoch: 9 cost=0.2431\n",
      "Epoch: 10 cost=0.2429\n",
      "Epoch: 11 cost=0.2436\n",
      "Epoch: 12 cost=0.2427\n",
      "Epoch: 13 cost=0.2439\n",
      "Epoch: 14 cost=0.2422\n",
      "Epoch: 15 cost=0.2426\n",
      "Epoch: 16 cost=0.2448\n",
      "Epoch: 17 cost=0.2418\n",
      "Epoch: 18 cost=0.2430\n",
      "Epoch: 19 cost=0.2431\n",
      "Epoch: 20 cost=0.2411\n",
      "Epoch: 21 cost=0.2408\n",
      "Epoch: 22 cost=0.2412\n",
      "Epoch: 23 cost=0.2380\n",
      "Epoch: 24 cost=0.2380\n",
      "Epoch: 25 cost=0.2382\n",
      "Epoch: 26 cost=0.2313\n",
      "Epoch: 27 cost=0.2269\n",
      "Epoch: 28 cost=0.2317\n",
      "Epoch: 29 cost=0.2233\n",
      "Epoch: 30 cost=0.2261\n",
      "Epoch: 31 cost=0.2217\n",
      "Epoch: 32 cost=0.2229\n",
      "Epoch: 33 cost=0.2199\n",
      "Epoch: 34 cost=0.2181\n",
      "Epoch: 35 cost=0.2185\n",
      "Epoch: 36 cost=0.2150\n",
      "Epoch: 37 cost=0.2095\n",
      "Epoch: 38 cost=0.2000\n",
      "Epoch: 39 cost=0.1972\n",
      "Epoch: 40 cost=0.1924\n",
      "Epoch: 41 cost=0.1885\n",
      "Epoch: 42 cost=0.1923\n",
      "Epoch: 43 cost=0.1815\n",
      "Epoch: 44 cost=0.1743\n",
      "Epoch: 45 cost=0.1743\n",
      "Epoch: 46 cost=0.1670\n",
      "Epoch: 47 cost=0.1672\n",
      "Epoch: 48 cost=0.1660\n",
      "Epoch: 49 cost=0.1643\n",
      "Epoch: 50 cost=0.1631\n",
      "Model has completed 49 Epochs of Training\n"
     ]
    }
   ],
   "source": [
    "sess.run(init)\n",
    "for epoch in range(epochs):\n",
    "    avg_cost=0.0\n",
    "    total_batchs=int(n_samples/batch_size)\n",
    "    for i in range(total_batchs):\n",
    "        batch_x=X_train[0+i*batch_size:50+i*batch_size]\n",
    "        batch_y=y_train[0+i*batch_size:50+i*batch_size]\n",
    "        \n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        avg_cost += c / total_batchs\n",
    "\n",
    "    print(\"Epoch: {} cost={:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of Training\".format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
